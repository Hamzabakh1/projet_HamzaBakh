# ðŸ’³ Credit Management Platform â€“ Data Engineering Project

**Author:** Hamza Bakh  
**Date:** October 2025  
---

## ðŸ§­ Overview

The **Credit Management Platform** is a full-stack data engineering project simulating how financial data is processed, validated, optimized, and exposed for analytics.  
It showcases an end-to-end workflow, covering:

- **Data ingestion**
- **Quality validation**
- **ETL orchestration**
- **Database optimization**
- **API design**
- **Schema migration**

All datasets are **synthetic** and rebuilt solely for educational and portfolio demonstration purposes.

---

## ðŸŽ¯ Objectives

- Automate ingestion and validation across multiple datasets  
- Maintain >99.9% data quality through systematic checks  
- Achieve <50 ms query latency with optimized indexing  
- Serve analytical insights through REST APIs  
- Enable backward-compatible schema migration for multi-currency support  

---

## âš™ï¸ Architecture Overview

| Layer | Technology | Purpose |
|-------|-------------|----------|
| **Data Layer** | SQLite | Lightweight relational storage |
| **Processing Layer** | Python (pandas, sqlite3) | ETL, validation, transformation |
| **API Layer** | Node.js (Express.js) | REST endpoints for analytics |
| **Migration Layer** | SQL scripts | Schema evolution & rollback |
| **Visualization Layer** | CSV / JSON exports | BI integration (Power BI-ready) |

---

## ðŸ“‚ Repository Structure

```plaintext
credit-management-platform/
â”‚
â”œâ”€â”€ credit_challenge_dataset/           # Synthetic dataset (CSV files)
â”‚
â”œâ”€â”€ part1_analysis/
â”‚   â””â”€â”€ credit_analysis.ipynb           # Business analysis & exploration
â”‚
â”œâ”€â”€ part2_data_quality/
â”‚   â”œâ”€â”€ data_quality.py                 # Validation framework
â”‚   â”œâ”€â”€ data_quality_report.csv         # Metrics summary
â”‚   â””â”€â”€ findings.md                     # Key insights & quality results
â”‚
â”œâ”€â”€ part3_etl/
â”‚   â”œâ”€â”€ etl_pipeline.py                 # Incremental ETL with idempotency
â”‚   â”œâ”€â”€ etl_execution.log               # Pipeline logs
â”‚   â””â”€â”€ etl_summary.json                # Load statistics
â”‚
â”œâ”€â”€ part4_optimization/
â”‚   â”œâ”€â”€ indexes.sql                     # Index optimization scripts
â”‚   â”œâ”€â”€ seller_health.js                # Analytics endpoint logic
â”‚   â”œâ”€â”€ server.js                       # Express.js API server
â”‚   â”œâ”€â”€ performance_report.md           # Benchmark & latency report
â”‚   â””â”€â”€ test_cases.md                   # API test documentation
â”‚
â””â”€â”€ part5_migration/
    â”œâ”€â”€ schema_design.sql               # Multi-currency schema design
    â”œâ”€â”€ migration.sql                   # Migration + rollback scripts
    â”œâ”€â”€ migration_runbook.md            # Step-by-step deployment guide
    â””â”€â”€ api_impact_analysis.md          # API change analysis
```

## ðŸš€ Quick Start

### Prerequisites
- Python â‰¥ 3.10  
- Node.js â‰¥ 18  
- SQLite 3.x  
- Git  

### Run Components
# 1ï¸âƒ£ Run data analysis
jupyter notebook part1_analysis/credit_analysis.ipynb

# 2ï¸âƒ£ Validate data quality
python part2_data_quality/data_quality.py

# 3ï¸âƒ£ Execute ETL pipeline
python part3_etl/etl_pipeline.py --db finance.db --run-all credit_challenge_dataset

# 4ï¸âƒ£ Start the API server
cd part4_optimization && npm install && node server.js

# 5ï¸âƒ£ Apply database migration
sqlite3 finance.db < part5_migration/migration.sql


## ðŸ“ Repository Structure

